{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structure:\n",
    "- Galaxies (group)\n",
    "  - Attributes(group)\n",
    "    - halo_ids (dataset)\n",
    "    - mass (dataset)\n",
    "    - ...\n",
    "  - Particles (group)\n",
    "    - DM (group)\n",
    "      - ...\n",
    "    - Stars (group)\n",
    "      - Maps (group)\n",
    "        - Mass (dataset)\n",
    "        - Metal (dataset)\n",
    "        - Age (dataset)\n",
    "      - ...\n",
    "    - Gas (group)\n",
    "      - ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os \n",
    "from galaxy import Galaxy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_data_structure(n_galaxies, image_res,galaxy_parameters, particle_types, fields, path=\"./\"):\n",
    "    '''Creates the HDF5 data structure for the galaxy data\n",
    "    #TODO: Add the ability to save the images as a 3D array\n",
    "    #TODO: Add the ability to set different fields for different particle types\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_galaxies: int\n",
    "        Number of galaxies to be saved\n",
    "    image_res: tuple\n",
    "        Image resolution (x,y) #TODO: Change to be flexible (x,y,z) for 3D images\n",
    "    galaxy_parameters: list\n",
    "        List of galaxy parameters to be saved\n",
    "    particle_types: list\n",
    "        List of particle types to be saved.\n",
    "    fields: dict\n",
    "        Dictionary of fields to be saved, where  key is the field name and the value is a boolean indicating if the field is mass weighted or not. \n",
    "        The fields are the same for all particle types and are saved in the \"Images\" group. The value is used to calculate the image later. #TODO maybe change this\n",
    "    path: str\n",
    "        Path to the HDF5 file\n",
    "    \n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    create_data_structure(1000, (64,64), galaxy_paramters=[\"mass\",\"halo_id\"], particle_types =[\"stars\"], {\"Masses\":False, \"GFM_Metallicity\":False, \"GFM_StellarFormationTime\":True})\n",
    "    \n",
    "    This will create a \"galaxy_data.hdf5\" HDF5 file with the following structure and save it to the current directory:\n",
    "    ---------------------------------------------------------\n",
    "    Galaxies\n",
    "        Attributes\n",
    "            mass\n",
    "            halo_id\n",
    "        Particles\n",
    "            stars\n",
    "                Images\n",
    "                    Masses\n",
    "                    GFM_Metallicity\n",
    "                    GFM_StellarFormationTime\n",
    "    ---------------------------------------------------------\n",
    "\n",
    "    '''\n",
    "    # Open the HDF5 file in \"w\" mode to create a new file\n",
    "    with h5py.File(os.path.join(path, \"galaxy_data.hdf5\"), \"w\") as f:\n",
    "        # Create the Galaxies group\n",
    "        galaxies_group = f.create_group(\"Galaxies\")\n",
    "        galaxy_attributes = galaxies_group.create_group(\"Attributes\")\n",
    "        # Create the datasets for the galaxy parameters\n",
    "        for parameter in galaxy_parameters:\n",
    "            galaxy_attributes.create_dataset(parameter, shape=(n_galaxies,), maxshape=(None,))    \n",
    "        \n",
    "        particles_group = galaxies_group.create_group(\"Particles\")\n",
    "        # Create the Particle Types group\n",
    "        for particle_type in particle_types:\n",
    "            particle_type_group = particles_group.create_group(particle_type)\n",
    "            \n",
    "            # Create the Images group\n",
    "            images_group = particle_type_group.create_group(\"Images\")\n",
    "            \n",
    "            # Create the datasets for the images\n",
    "            for field in fields:\n",
    "                images_group.create_dataset(field, shape=(n_galaxies, *image_res), maxshape=(None, None,None))\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "def _calculate_images(simulation,halo_ids,fields,plot_factor, image_res, path=\"./\",**kwargs):\n",
    "    '''Calculates the images for the galaxies and saves them to the HDF5 file. Needs to be run after _create_data_structure() method.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    simulation: str\n",
    "        Simulation name (e.g. IllustrisTNG). Used to initialise the Galaxy class. The Galaxy class for a specific simulation should be defined in the simulations.py file. #TODO: Change name\n",
    "    halo_ids: list\n",
    "        List of halo IDs to calculate the images for. The halo_ids are used to load the galaxy data from the simulation.\n",
    "    fields: dict\n",
    "        Dictionary of fields to be saved. The key is the field name and the value is a boolean indicating if the calculated field image should mass weighted or not.\n",
    "            e.g {\"Masses\":False, \"GFM_Metallicity\":False, \"GFM_StellarFormationTime\":True}\n",
    "    plot_factor: float\n",
    "        Factor for the image range. The image range is calculated as halfmass_radius*plot_factor and the image is centred on the galaxy centre.\n",
    "        For the halfmass_radius only the particle type specified in the particle_type argument are used.\n",
    "    path: str\n",
    "        Path to the HDF5 file to save the data to. This file should be created using create_data_structure() method.\n",
    "    **kwargs: dict\n",
    "        Keyword arguments passed to the Galaxy class. Halo ID and particle type are overwritten in the loop.\n",
    "        e.g. {\"base_path\":basePath,\"halo_id\":0,\"particle_type\": \"stars\", \"snapshot\":99} for IllustrisTNG\n",
    "\n",
    "    '''\n",
    "    # Check if the HDF5 file exists, which should be created using create_data_structure() method.\n",
    "    if not os.path.exists(os.path.join(path, \"galaxy_data.hdf5\")):\n",
    "        raise FileNotFoundError(f\"{os.path.join(path, 'galaxy_data.hdf5')} does not exist. This should have been created using the _create_data_structure() method.\")\n",
    "    \n",
    "    n_galaxies = len(halo_ids)\n",
    "    # Open the HDF5 file in \"append\" mode\n",
    "    with h5py.File(os.path.join(path,\"galaxy_data.hdf5\"), \"a\") as f:\n",
    "        \n",
    "        # Check if the \"index_position\" attribute exists\n",
    "        if \"index_position\" in f.attrs:\n",
    "            index_position = f.attrs[\"index_position\"]\n",
    "            \n",
    "            # Ask the user if they want to continue from the last index position\n",
    "            if input(f\"Continue from index position {index_position}? (y/n): \") == \"y\":\n",
    "                # Check if the index position is valid\n",
    "                if index_position > n_galaxies:\n",
    "                    raise ValueError(f\"Index position {index_position} is greater than the number of galaxies {n_galaxies}\")        \n",
    "            else:\n",
    "                # Reset the index position since the user does not want to continue from the last index position \n",
    "                index_position = 0\n",
    "        else:\n",
    "            #Attribute does not exist so set the index position to 0 to start the loop from the beginning\n",
    "            index_position = 0\n",
    "\n",
    "        \n",
    "        \n",
    "        # Loop through the galaxies\n",
    "        for index, haloid in tqdm(enumerate(halo_ids[index_position:])):\n",
    "            # Create the galaxy object\n",
    "            kwargs[\"halo_id\"] = haloid\n",
    "            \n",
    "            g = Galaxy(simulation= simulation, **kwargs) \n",
    "            \n",
    "            # Get the galaxy parameters\n",
    "            for parameter in f[\"Galaxies/Attributes\"].keys():\n",
    "                if hasattr(g,parameter):\n",
    "                    f[\"Galaxies/Attributes\"][parameter][index] = getattr(g,parameter)\n",
    "                else: \n",
    "                    raise ValueError(f\"Galaxy class does not have the attribute {parameter}\")\n",
    "                \n",
    "            # Get the particle data\n",
    "            for particle_type in f[\"Galaxies\"][\"Particles\"].keys():\n",
    "                # Get the particle data\n",
    "                for field in f[\"Galaxies\"][\"Particles\"][particle_type][\"Images\"].keys():\n",
    "                    # Get the image\n",
    "                    image = g.get_image(field, plot_factor, image_res, mass_weighted=fields[field])\n",
    "                    f[\"Galaxies\"][\"Particles\"][particle_type][\"Images\"][field][index] = image\n",
    "            \n",
    "            # Update the index position\n",
    "            f.attrs[\"index_position\"] += 1\n",
    "            \n",
    "        # Show the user that the images have been calculated\n",
    "        print(\"Images calculated and saved to HDF5 file: \", os.path.join(path,\"galaxy_data.hdf5\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the parameters\n",
    "simulation = \"IllustrisTNG\" # Simulation name\n",
    "particle_types = [\"stars\"] # Particle types\n",
    "image_res = (64,64) # Image resolution\n",
    "halo_ids= [15,20]\n",
    "\n",
    "\n",
    "path = \"./\"\n",
    "\n",
    "fields = {\"Masses\":False, \n",
    "          \"GFM_Metallicity\":False,\n",
    "          \"GFM_StellarFormationTime\":True} # Fields to calculated images for and if they are mass weighted or not\n",
    "plot_factor = 10 # Plot factor for the image: plot_factor*halfmassrad = image range\n",
    "\n",
    "galaxy_parameters = [\"mass\",\"halo_id\"] # Attributes of Galaxy Class to be saved for each galaxy (TODO: This atm only works for scalar parameters)\n",
    "basePath = f\"/export/data/ucakir/TNG100/TNG100-1/output/\"\n",
    "\n",
    "# Arguments passed to the galaxy class. Halo ID and particle type are overwritten in the loop.\n",
    "kwargs = {\"base_path\":basePath,\"halo_id\":0,\"particle_type\": \"stars\", \"snapshot\":99}\n",
    "\n",
    "\n",
    "# Open the HDF5 file in \"w\" mode to create a new file\n",
    "\n",
    "# Check if galaxy_data.hdf5 exists\n",
    "if os.path.exists(os.path.join(path, \"galaxy_data.hdf5\")):\n",
    "    # Ask the user if they want to overwrite the file\n",
    "    if input(f\"{os.path.join(path, 'galaxy_data.hdf5')} already exists. Do you want to overwrite it? (y/n)\") == \"y\":\n",
    "        # Overwrite the file\n",
    "        create_data_structure(galaxy_parameters, particle_types, fields, path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = np.random.randint(0,255, size=(64,64))\n",
    "mass = np.random.randint(0,255, size=(64,64))\n",
    "\n",
    "\n",
    "#Avoid division by zero\n",
    "mask = np.where(mass !=0)\n",
    "div = np.zeros_like(img)\n",
    "div[mask] = img[mask]/mass[mask]\n",
    "\n",
    "# div = np.where(mass !=0, img/mass, img)\n",
    "plt.imshow(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File(\"galaxy_data.hdf5\", \"r\")\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(file[\"Galaxies/Particles/stars/Images/Masses\"][1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Mass\" in \"SubhaloMassType\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate import generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = f\"/export/data/ucakir/TNG100/TNG100-1/output/\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fields = {\"Masses\":{\"mass_weighted\": False,\n",
    "                    \"normed\": False,\n",
    "                    \"plusone\": True,\n",
    "                    \"log\": True,\n",
    "                        }, \n",
    "          \n",
    "          \"GFM_Metallicity\":\n",
    "              {\"mass_weighted\": False,\n",
    "                    \"normed\": True,\n",
    "                    \"plusone\": True,\n",
    "                    \"takelog\": True,\n",
    "            }, \n",
    "          \"GFM_StellarFormationTime\":\n",
    "              {\"mass_weighted\": True,\n",
    "                    \"normed\": True,\n",
    "                    \"plusone\": True,\n",
    "                    \"takelog\": True,\n",
    "                        }} # Fields to calculated images for and if they are mass weighted or not\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "generate_data(simulation = \"IllustrisTNG\", halo_ids=[15,20], fields=fields, \n",
    "              plot_factor=10, image_res=(64,64), path=\"./\", particle_types=[\"stars\"], galaxy_parameters=[\"mass\",\"halo_id\"],\n",
    "              **{\"base_path\":basePath,\"halo_id\":0,\"particle_type\": \"stars\", \"snapshot\":99})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "with h5py.File(\"galaxy_data.hdf5\", \"r\") as f:\n",
    "    plt.imshow(f[\"Galaxies/Particles/stars/Images/Masses\"][1])\n",
    "    plt.imshow(f[\"Galaxies/Particles/stars/Images/GFM_Metallicity\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load(\"/export/home/ucakir/galaxy-morphology/experiments/corrupt_haloids.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.load(\"/export/home/ucakir/galaxy-morphology/experiments/data/deeplearn_ids.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the halo ids are in the corrupt halo ids\n",
    "check = np.isin(ids, test)\n",
    "\n",
    "# Get the indices of the corrupt halo ids\n",
    "corr = ids[check]\n",
    "print(corr)\n",
    "\n",
    "#delete the corrupt halo ids and save the new array\n",
    "new_ids = np.delete(ids, np.where(check))\n",
    "\n",
    "np.save(\"deep_ids_wihtout_corrupt.npy\", new_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.shape, new_ids.shape, ids.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with h5py.File(\"galaxy_data.hdf5\", \"r\") as f:\n",
    "    n, x, y = f[\"Galaxies/Particles/stars/Images/Masses\"].shape\n",
    "    reshaped = np.empty((n, x*y), dtype = f[\"Galaxies/Particles/stars/Images/Masses\"].dtype)\n",
    "    hyperslab = (slice(None), slice(None), slice(None))\n",
    "    # output to a 2D array\n",
    "    output_hyperslab=(slice(None), slice(None))\n",
    "    f[\"Galaxies/Particles/stars/Images/Masses\"].resize((n, x*y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields={\"Masses\":False, \"GFM_Metallicity\":False, \"GFM_StellarFormationTime\":True}\n",
    "fields[\"Masses\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\"1\":0}\n",
    "# Check if dictionary is empty\n",
    "if not test:\n",
    "    print(\"Empty\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

import h5py
import numpy as np
import matplotlib.pyplot as plt
import numpy as np
from sklearn.decomposition import PCA

# Helper function to print the structure of an hdf5 file
#TODO Move this to a separate file
def print_hdf5_file_structure(file_path):
    with h5py.File(file_path, 'r') as f:
        print(f"File: {file_path}")
        print_hdf5_group_structure(f)

def print_hdf5_group_structure(group, indent=0):
    for key in group.keys():
        sub_group = group[key]
        if isinstance(sub_group, h5py.Group):
            print("{0}Group: {1}".format(" " * indent, key))
            print_hdf5_group_structure(sub_group, indent + 4)
        else:
            print("{0}Dataset: {1} ({2})".format(" " * indent, key, sub_group.dtype))

# Maybe move this to data folder


#How to acces HDF5 data most efficiently? ?
class DataLoader():
    
    def __init__(self,path, show_structure = True):
        self.path = path
        self._load_keys()
        if show_structure:
            self.show_structure()
    def _load_keys(self):
        
        # Load the data from the hdf5 file generated by the generate_data.py script without loading into memory
        with h5py.File(self.path, 'r') as f:
            self._galaxy_attributes_keys = [keys for keys in f["Galaxies/Attributes"].keys()]
            self._particles_keys = [keys for keys in f["Galaxies/Particles"].keys()]
            # Load the fields of the images
            self._image_fields = dict()
            for particle in f["Galaxies/Particles"].keys():
                particle_field = []
                for field in f["Galaxies/Particles"][particle]["Images"].keys():
                    particle_field.append(field)
                self._image_fields[particle] = particle_field
    def get_attribute(self, attribute, index = None):
        '''Get a galaxy attribute.
        
        If index is None, return all specific attribute of all galaxies. Otherwise, return the attribute of the specified index in the dataset.
        
        Parameters:
        -----------
            attribute : str
                The attribute to return. Must be a valid attribute, otherwise a ValueError is raised.
            index : int, optional
                The galaxy index in the dataset to return. If None, return all galaxies.
            
        Returns:
        --------
            attribute : np.ndarray
                The attribute of the specified galaxy index in the dataset.

        Example:
        --------
            >>> data = DataLoader("data.hdf5")
            >>> data.get_attribute("mass") # Get the mass of all galaxies in the dataset
            >>> data.get_attribute("mass", 10) # Get the mass of the 10th galaxy in the dataset
            

        
        
        
        
        '''
        
        #Check if the attribute is valid
        if attribute not in self._galaxy_attributes_keys:
            raise ValueError(f"Attribute {attribute} not found. Valid attributes are: {self._galaxy_attributes_keys}")
        
        # Open the hdf5 file in read-only mode
        with h5py.File(self.path, 'r') as f:
            if index is None:
                return f["Galaxies/Attributes"][attribute][()]
            else:
                return f["Galaxies/Attributes"][attribute][index]
        
   
    
    def get_image(self, particle_type, field, index=None):
        '''Get the image of the specified particle type and field.
        
        If index is None, return all images. Otherwise, return the galaxy image of the specified index and field in the dataset.
        
        Parameters:    
        ------------
            particle_type : str
                The particle type of the image. 
            field : str
                The field of the image.     
            index : int, optional
                The galaxy index ind the dataset to return. If None, return all images.    
            
        Returns:
        --------
            image : np.ndarray
                The image of the specified particle type and field.

        Examples:
        ---------
            >>> data = DataLoader("data.hdf5")
            >>> image = data.get_image("stars", "Masses", 10) # Get the stars masses image of the 10th galaxy in the dataset
            >>> all_images = data.get_image("stars", "Masses") # Get all stars masses images in the dataset 
            '''
        #Check if the particle type is valid
        if particle_type not in self._particles_keys:
            raise ValueError(f"Particle type {particle_type} not found. Valid particle types are: {self._particles_keys}")
        #Check if the field is valid
        if field not in self._image_fields[particle_type]:
            raise ValueError(f"Field {field} not found. Valid fields are: {self._image_fields[particle_type]}")
        
        # OPen the hdf5 file in read-only mode
        with h5py.File(self.path, 'r') as f:
            if index is None:
                return f[f"Galaxies/Particles/{particle_type}/Images/{field}"][()]
            else:
                return f[f"Galaxies/Particles/{particle_type}/Images/{field}"][index]
           
    def show_structure(self):
        '''Print the structure of the hdf5 file
        Examples:
        ---------
            >>> data = DataLoader("data.hdf5")
            >>> data.show_structure()
                File: data.hdf5
                Group: Galaxies
                    Group: Attributes
                        Dataset: halo_id (int64)
                        Dataset: mass (float64)
                
                    Group: Particles
                        Group: stars
                            Group: Images
                                Dataset: Masses (np.ndarray)
                                Dataset: GFM_Metallicity (np.ndarray)
                        Group: gas
                            Group: Images
                                Dataset: Masses (np.ndarray)
        '''
        print_hdf5_file_structure(self.path)



class mPCA():
    
    def __init__(self,data, particle_type = None, norm_function = None, norm_function_kwargs=None):
        # Check if data is instance of DataLoader
        if not isinstance(data, DataLoader):
            raise ValueError("data must be an instance of DataLoader")
        
        # Set the particle type on which to apply the PCA (TODO maybe add option to apply PCA on multiple particle types)
        if particle_type is None:
           # Check if data has multiple particle types
            if len(data._particles_keys) > 1:
                raise ValueError("PCA can only be applied to a single particle type. Please select a single particle type when initializing the PCA object.")
            else:
                # Set the particle type to the only particle type in the dataset
                self.particle_type = data._particles_keys[0]
        else:
            #Check if the particle type is valid
            if particle_type not in data._particles_keys:
                raise ValueError(f"Particle type {particle_type} not found. Valid particle types are: {data._particles_keys}")
            else:
                self.particle_type = particle_type
        self.data = data
        self._norm_function = norm_function
        self._norm_function_kwargs = norm_function_kwargs
        self._IMG_ORDER = self.data._image_fields[self.particle_type]
        self._IMG_SHAPE = self.data.get_image(self.particle_type, self.data._image_fields[self.particle_type][0], index = 0).shape
        # Initialize the datamatrix to of shape (n_galaxies, 0)
        self.datamatrix = np.empty((data.get_attribute("mass").shape[0], 0)) 
        # Create datamatrix
        self._create_datamatrix()
        
        #Get the image shape of one galaxy image
        

            
    def _create_datamatrix(self):
        # Get the fields images of the specified particle type
        
        print("Creating datamatrix with the following fields:")
        print("===============================================")
        print("Particle type: ", self.particle_type)
        print("Fields: ", self.data._image_fields[self.particle_type])
        print("norm_function_kwargs: ", self._norm_function_kwargs)
        # Say that for the fields that are not specified in the norm_function_kwargs, the default arguments are used
        print("Default arguments are used for the fields that are not specified in the norm_function_kwargs")
        print("===============================================")
        
        
        
        
        
        # (!) Reshape not working properly??
        for field in self.data._image_fields[self.particle_type]:
            # Get the image of the specified particle type and field
            image = self.data.get_image(self.particle_type, field)
            # Flatten each image to a 1D array
            #image = image.reshape(image.shape[0], np.prod(self._IMG_SHAPE))
            image = np.array([img.flatten() for img in image])
            # Normalize the image
            if self._norm_function is not None:
                # Check if the norm function has arguments for the specified field
                if field in self._norm_function_kwargs.keys():
                    image = self._norm_function(image, **self._norm_function_kwargs[field])
                else:
                    # If no arguments are specified, use the default arguments
                    image = self._norm_function(image)
            # Add the image to the datamatrix
            self.datamatrix = np.concatenate((self.datamatrix, image), axis=1)
            
        print("Created datamatrix with shape: ", self.datamatrix.shape)
        
        
        
    def fit(self, n_components=None, show_results = True,**kwargs):
        '''Fit the PCA to the datamatrix
        
        Parameters:
        -----------
            n_components : int, optional
                Number of components to keep. If None, all components are kept.
            **kwargs : dict, optional
                Keyword arguments to pass to the sklearn PCA object.
        '''
        self.pca = PCA(n_components=n_components, **kwargs)
        self.scores = self.pca.fit_transform(self.datamatrix)
        self.eigengalaxies = self.pca.components_.reshape(self.pca.components_.shape[0],len(self.data._image_fields[self.particle_type]), *self._IMG_SHAPE)
        self.inverse_transformed_datamatrix = self.pca.inverse_transform(self.scores)
        if show_results:
            self.show_results()
            
    def show_results(self):
        fig, ax = plt.subplots(1, 2, figsize=(10, 5))
        ax[0].plot(self.pca.explained_variance_ratio_)
        ax[0].set_xlabel("Component")
        ax[0].set_ylabel("Explained variance ratio")
        ax[1].plot(np.cumsum(self.pca.explained_variance_ratio_))
        ax[1].set_xlabel("Component")
        ax[1].set_ylabel("Cumulative explained variance ratio")
        plt.show()

        
        #Loop over different image fields
        for index,field in enumerate(self.data._image_fields[self.particle_type]):

            #Plot the eigengalaxies in a grid
            #get the number of rows and columns
        
            rows = int(np.ceil(np.sqrt(self.pca.n_components)))
            cols = int(np.ceil(self.pca.n_components/rows))
            fig, ax = plt.subplots(rows, cols, figsize=(cols*3, rows*3))
            for i in range(rows):
                for j in range(cols):
                    if i*cols+j < self.pca.n_components:
                        ax[i, j].imshow(self.eigengalaxies[i*cols+j][index])
                        ax[i, j].set_title(f"Component {i*cols+j}")
                        ax[i, j].axis("off")
            fig.suptitle(f"Eigengalaxies:{field}")
            plt.show()